{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIgxqm09zYQl"
   },
   "outputs": [],
   "source": [
    "# See through the cifar-10 dataset and display some image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0xfBdxM0F8m",
    "outputId": "306b1288-4c3b-470d-99f1-b3e28d83fc6a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "drive_path = \"/content/drive/My Drive/CIFAR10\"\n",
    "os.makedirs(drive_path, exist_ok=True)"
   ],
   "metadata": {
    "id": "qqwschPF0T0E"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Download CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=drive_path, train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=drive_path, train=False, download=True, transform=transform\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sztraQJO0zw4",
    "outputId": "c0346aed-4292-4052-cd24-931b6a7077fb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/My Drive/CIFAR10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 170M/170M [00:03<00:00, 43.5MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting /content/drive/My Drive/CIFAR10/cifar-10-python.tar.gz to /content/drive/My Drive/CIFAR10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "len(train_dataset), len(test_dataset)  # 50000 train and 10000 test data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXTUjFp71zn8",
    "outputId": "88af5e5d-4438-4ac8-8469-c86de9a5ded9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Access one instance from the train_dataset\n",
    "image, label = train_dataset[\n",
    "    10\n",
    "]  # Replace 0 with any index to view a different instance\n",
    "\n",
    "# Convert the image tensor to a NumPy array for visualization\n",
    "image = np.transpose(\n",
    "    image.numpy(), (1, 2, 0)\n",
    ")  # Rearrange dimensions from (C, H, W) to (H, W, C)\n",
    "\n",
    "# CIFAR-10 class names\n",
    "classes = (\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "\n",
    "# Display the image with its label\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Label: {classes[label]}\")  # Map the label to its class name\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "c8rBdja819nP",
    "outputId": "dba8983c-3271-4e86-c66b-3ba772e6016f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert train and test datasets to tensors\n",
    "train_images_tensor = torch.stack(\n",
    "    [train_dataset[i][0] for i in range(len(train_dataset))]\n",
    ")\n",
    "train_labels_tensor = torch.tensor(\n",
    "    [train_dataset[i][1] for i in range(len(train_dataset))]\n",
    ")\n",
    "\n",
    "test_images_tensor = torch.stack([test_dataset[i][0] for i in range(len(test_dataset))])\n",
    "test_labels_tensor = torch.tensor(\n",
    "    [test_dataset[i][1] for i in range(len(test_dataset))]\n",
    ")\n",
    "\n",
    "print(f\"Train images tensor shape: {train_images_tensor.shape}\")\n",
    "print(f\"Train labels tensor shape: {train_labels_tensor.shape}\")\n",
    "print(f\"Test images tensor shape: {test_images_tensor.shape}\")\n",
    "print(f\"Test labels tensor shape: {test_labels_tensor.shape}\")\n",
    "\n",
    "# Convert tensors to NumPy arrays\n",
    "train_images_numpy = train_images_tensor.numpy()\n",
    "train_labels_numpy = train_labels_tensor.numpy()\n",
    "\n",
    "test_images_numpy = test_images_tensor.numpy()\n",
    "test_labels_numpy = test_labels_tensor.numpy()\n",
    "\n",
    "print(f\"Train images NumPy shape: {train_images_numpy.shape}\")\n",
    "print(f\"Train labels NumPy shape: {train_labels_numpy.shape}\")\n",
    "print(f\"Test images NumPy shape: {test_images_numpy.shape}\")\n",
    "print(f\"Test labels NumPy shape: {test_labels_numpy.shape}\")\n",
    "\n",
    "\n",
    "# Clear tensors from memory\n",
    "del train_images_tensor\n",
    "del train_labels_tensor\n",
    "del test_images_tensor\n",
    "del test_labels_tensor\n",
    "\n",
    "# Force garbage collection to free up memory\n",
    "gc.collect()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMBLrneX4axc",
    "outputId": "e40d9cc5-dc3f-4062-caa4-8d81802ff8e4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train images tensor shape: torch.Size([50000, 3, 32, 32])\n",
      "Train labels tensor shape: torch.Size([50000])\n",
      "Test images tensor shape: torch.Size([10000, 3, 32, 32])\n",
      "Test labels tensor shape: torch.Size([10000])\n",
      "Train images NumPy shape: (50000, 3, 32, 32)\n",
      "Train labels NumPy shape: (50000,)\n",
      "Test images NumPy shape: (10000, 3, 32, 32)\n",
      "Test labels NumPy shape: (10000,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_images_numpy[0].shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xd_vPotM6AcM",
    "outputId": "334c4338-cf94-4bda-ad3c-d5dac478c3bc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_images_numpy[0].min(), train_images_numpy[0].max()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lKdaFFl6EmD",
    "outputId": "5d4abe45-a7b0-4f19-9643-225637e0c058"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## MMP's code below\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "\n",
    "\n",
    "class cnn:\n",
    "    def __init__(self, input_size, num_kernels, kernel_size):\n",
    "        self.input_size = input_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_kernels = num_kernels\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"cnn(num_input={self.num_input}, num_output={self.num_output}, \"\n",
    "            f\"kernel_size={self.kernel_size}, stride={self.stride}, padding={self.padding})\"\n",
    "        )\n",
    "\n",
    "    def generate_cnn_patches(self, image, stride, padding):\n",
    "        num_channel, image_h, image_w = image.shape\n",
    "\n",
    "        # Determine kernel size\n",
    "        if isinstance(self.kernel_size, int):\n",
    "            kernel_h = kernel_w = self.kernel_size\n",
    "\n",
    "        elif isinstance(self.kernel_size, tuple):\n",
    "            kernel_h, kernel_w = self.kernel_size\n",
    "\n",
    "        # Add padding if necessary\n",
    "        if padding > 0:\n",
    "            padded_image = np.pad(\n",
    "                image,\n",
    "                pad_width=((0, 0), (padding, padding), (padding, padding)),\n",
    "                mode=\"constant\",\n",
    "                constant_values=0,\n",
    "            )\n",
    "        else:\n",
    "            padded_image = image\n",
    "\n",
    "        # Initialize storage for patches\n",
    "        patches = []\n",
    "\n",
    "        for channel in range(num_channel):\n",
    "            channel_patch = []\n",
    "\n",
    "            for i in range(0, image_h - kernel_h + 1, stride):\n",
    "\n",
    "                for j in range(0, image_w - kernel_w + 1, stride):\n",
    "                    patch = padded_image[channel, i : i + kernel_h, j : j + kernel_w]\n",
    "                    channel_patch.append(patch)\n",
    "\n",
    "            channel_patch = np.array(channel_patch)\n",
    "            patches.append(channel_patch)\n",
    "\n",
    "        patches = np.array(patches)\n",
    "\n",
    "        return patches\n",
    "\n",
    "    def convolute(self, patch, kernel):\n",
    "        conv_mat = signal.correlate2d(patch, kernel, mode=\"valid\")\n",
    "\n",
    "        return conv_mat\n",
    "\n",
    "    def convolve(self, img, stride, padding):\n",
    "\n",
    "        patches = self.generate_cnn_patches(img, stride, padding)\n",
    "        num_channels, input_h, input_w = (\n",
    "            img.shape\n",
    "        )  ##need to indexing value for right shape\n",
    "\n",
    "        self.output_shape = (\n",
    "            self.num_kernels,\n",
    "            input_h - self.kernel_size + 1,\n",
    "            input_w - self.kernel_size + 1,\n",
    "        )\n",
    "        self.kernels_shape = (\n",
    "            self.num_kernels,\n",
    "            num_channels,\n",
    "            self.kernel_size,\n",
    "            self.kernel_size,\n",
    "        )\n",
    "        self.kernels = np.random.rand(*self.kernels_shape)\n",
    "        self.biases = np.random.rand(*self.output_shape)\n",
    "        self.output = np.zeros(\n",
    "            (\n",
    "                self.num_kernels,\n",
    "                input_h - self.kernel_size + 1,\n",
    "                input_w - self.kernel_size + 1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\"kernels = \", self.kernels)\n",
    "\n",
    "        for i in range(self.num_kernels):\n",
    "            y = 0\n",
    "            for kernel in self.kernels[i]:\n",
    "                l = 0\n",
    "                k = 0\n",
    "                for patch in patches[y]:\n",
    "                    self.output[i][k][l] += self.convolute(patch, kernel)\n",
    "                    l += 1\n",
    "\n",
    "                    if l >= input_w - self.kernel_size + 1:\n",
    "                        l = 0\n",
    "                        k += 1\n",
    "                y += 1\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    # def max_pooling(self, convolved_img, stride)\n",
    "\n",
    "    # def generate_cnn_patches(self, image):\n",
    "    #     num_channel, image_h, image_w = image.shape\n",
    "\n",
    "    #     if isinstance(self.kernel_size, int):\n",
    "    #         kernel_h = kernel_w = self.kernel_size\n",
    "    #     elif isinstance(self.kernel_size, tuple):\n",
    "    #         kernel_h, kernel_w = self.kernel_size\n",
    "\n",
    "    #     if self.padding > 0:\n",
    "    #         image = np.pad(image, pad_width=((self.padding, self.padding), (self.padding, self.padding) (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "    #     output_height = (image_h -  kernel_h) // self.stride + 1\n",
    "    #     output_width = (image_w - kernel_w) // self.stride + 1\n",
    "\n",
    "    #     patches = []\n",
    "\n",
    "    #     for i in range(0, output_height - kernel_h + 1, self.stride):\n",
    "    #         for j in range(0, output_width - kernel_w + 1, self.stride):\n",
    "    #             patch = image[i:i+kernel_h, j:kernel_w, :]\n",
    "    #             patches.append(patch)\n",
    "\n",
    "    #     return patches"
   ],
   "metadata": {
    "id": "YBBhE6GB9Glu"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}